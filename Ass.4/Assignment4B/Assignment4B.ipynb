{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport keras\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.datasets import cifar10\nimport numpy as np\nimport os\n\n# Training parameters\nbatch_size = 128  # orig paper trained all networks with batch_size=128\nepochs = 50\ndata_augmentation = True\nnum_classes = 10\nrandom_erasing = True\n\n# Subtracting pixel mean improves accuracy\nsubtract_pixel_mean = True\nn = 3\n\n# Model version\n# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\nversion = 1\n\n# Computed depth from supplied model parameter n\nif version == 1:\n    depth = n * 6 + 2\nelif version == 2:\n    depth = n * 9 + 2\n\n# Model name, depth and version\nmodel_type = 'ResNet%dv%d' % (depth, version)\n\n# Load the CIFAR10 data.\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# Input image dimensions.\ninput_shape = x_train.shape[1:]\n\n# Normalize data.\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\n# If subtract pixel mean is enabled\nif subtract_pixel_mean:\n    x_train_mean = np.mean(x_train, axis=0)\n    x_train -= x_train_mean\n    x_test -= x_train_mean\n\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint('y_train shape:', y_train.shape)\n\n# Convert class vectors to binary class matrices.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\ndef lr_schedule(epoch):\n    lr = 1e-3\n    if epoch > 180:\n        lr *= 0.5e-3\n    elif epoch > 160:\n        lr *= 1e-3\n    elif epoch > 120:\n        lr *= 1e-2\n    elif epoch > 80:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr\n\ndef resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x\n\n\ndef resnet_v1(input_shape, depth, num_classes=10):\n    if (depth - 2) % 6 != 0:\n        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n    # Start model definition.\n    num_filters = 16\n    num_res_blocks = int((depth - 2) / 6)\n\n    inputs = Input(shape=input_shape)\n    x = resnet_layer(inputs=inputs)\n    # Instantiate the stack of residual units\n    for stack in range(3):\n        for res_block in range(num_res_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                strides = 2  # downsample\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             strides=strides)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n            x = Activation('relu')(x)\n        num_filters *= 2\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\ndef resnet_v2(input_shape, depth, num_classes=10):\n    if (depth - 2) % 9 != 0:\n        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n    # Start model definition.\n    num_filters_in = 16\n    num_res_blocks = int((depth - 2) / 9)\n\n    inputs = Input(shape=input_shape)\n    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n    x = resnet_layer(inputs=inputs,\n                     num_filters=num_filters_in,\n                     conv_first=True)\n\n    # Instantiate the stack of residual units\n    for stage in range(3):\n        for res_block in range(num_res_blocks):\n            activation = 'relu'\n            batch_normalization = True\n            strides = 1\n            if stage == 0:\n                num_filters_out = num_filters_in * 4\n                if res_block == 0:  # first layer and first stage\n                    activation = None\n                    batch_normalization = False\n            else:\n                num_filters_out = num_filters_in * 2\n                if res_block == 0:  # first layer but not first stage\n                    strides = 2    # downsample\n\n            # bottleneck residual unit\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters_in,\n                             kernel_size=1,\n                             strides=strides,\n                             activation=activation,\n                             batch_normalization=batch_normalization,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_in,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_out,\n                             kernel_size=1,\n                             conv_first=False)\n            if res_block == 0:\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters_out,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n\n        num_filters_in = num_filters_out\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\n\nif version == 2:\n    model = resnet_v2(input_shape=input_shape, depth=depth)\nelse:\n    model = resnet_v1(input_shape=input_shape, depth=depth)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=0),\n              metrics=['accuracy'])\nmodel.summary()\nprint(model_type)\n\n# Prepare model model saving directory.\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nfilepath = os.path.join(save_dir, model_name)\n\n# Prepare callbacks for model saving and for learning rate adjustment.\ncheckpoint = ModelCheckpoint(filepath=filepath,\n                             monitor='val_acc',\n                             verbose=1,\n                             save_best_only=True)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\ncallbacks = [checkpoint, lr_reducer, lr_scheduler]\n\n# Run training, with or without data augmentation.\nif not data_augmentation:\n    print('Not using data augmentation.')\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True,\n              callbacks=callbacks)\nelse:\n    print('Using real-time data augmentation.')\n    # This will do preprocessing and realtime data augmentation:\n    datagen = ImageDataGenerator(\n        # set input mean to 0 over the dataset\n        featurewise_center=False,\n        # set each sample mean to 0\n        samplewise_center=False,\n        # divide inputs by std of dataset\n        featurewise_std_normalization=False,\n        # divide each input by its std\n        samplewise_std_normalization=False,\n        # apply ZCA whitening\n        zca_whitening=False,\n        # epsilon for ZCA whitening\n        zca_epsilon=1e-06,\n        # randomly rotate images in the range (deg 0 to 180)\n        rotation_range=0,\n        # randomly shift images horizontally\n        width_shift_range=0.1,\n        # randomly shift images vertically\n        height_shift_range=0.1,\n        # set range for random shear\n        shear_range=0.,\n        # set range for random zoom\n        zoom_range=0.,\n        # set range for random channel shifts\n        channel_shift_range=0.,\n        # set mode for filling points outside the input boundaries\n        fill_mode='nearest',\n        # value used for fill_mode = \"constant\"\n        cval=0.,\n        # randomly flip images\n        horizontal_flip=True,\n        # randomly flip images\n        vertical_flip=False,\n        # set rescaling factor (applied before any other transformation)\n        rescale=None,\n        # set function that will be applied on each input\n        preprocessing_function=None,\n        # image data format, either \"channels_first\" or \"channels_last\"\n        data_format=None,\n        # fraction of images reserved for validation (strictly between 0 and 1)\n        validation_split=0.0)\n\n    datagen.fit(x_train)\n\n    # Fit the model on the batches generated by datagen.flow().\n    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                        validation_data=(x_test, y_test),\n                        epochs=epochs, verbose=1, workers=4,\n                        callbacks=callbacks)\n\n# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 2s 0us/step: \nx_train shape: (50000, 32, 32, 3)\n50000 train samples\n10000 test samples\ny_train shape: (50000, 1)\nModel: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n                                                                 batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n                                                                 batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n                                                                 batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  \n                                                                 batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n                                                                 batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n                                                                 batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  \n                                                                 batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n                                                                 batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n                                                                 batch_normalization_19[0][0]     \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n__________________________________________________________________________________________________\naverage_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n==================================================================================================\nTotal params: 274,442\nTrainable params: 273,066\nNon-trainable params: 1,376\n__________________________________________________________________________________________________\nResNet20v1\nUsing real-time data augmentation.\n","name":"stdout"},{"output_type":"stream","text":"Epoch 1/50\nLearning rate:  0.001\n391/391 [==============================] - 47s 120ms/step - loss: 1.7092 - accuracy: 0.4407 - val_loss: 2.1031 - val_accuracy: 0.3987\nEpoch 2/50\nLearning rate:  0.001\n  1/391 [..............................] - ETA: 40s - loss: 1.4737 - accuracy: 0.5234","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n  'skipping.' % (self.monitor), RuntimeWarning)\n","name":"stderr"},{"output_type":"stream","text":"391/391 [==============================] - 35s 90ms/step - loss: 1.2981 - accuracy: 0.5879 - val_loss: 1.6044 - val_accuracy: 0.5162\nEpoch 3/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 1.1026 - accuracy: 0.6592 - val_loss: 1.3417 - val_accuracy: 0.6094\nEpoch 4/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.9800 - accuracy: 0.7076 - val_loss: 1.4582 - val_accuracy: 0.5917\nEpoch 5/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.8913 - accuracy: 0.7394 - val_loss: 1.3130 - val_accuracy: 0.6168\nEpoch 6/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.8244 - accuracy: 0.7647 - val_loss: 1.6415 - val_accuracy: 0.5782\nEpoch 7/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.7789 - accuracy: 0.7804 - val_loss: 1.5408 - val_accuracy: 0.6178\nEpoch 8/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 86ms/step - loss: 0.7427 - accuracy: 0.7920 - val_loss: 0.8699 - val_accuracy: 0.7574\nEpoch 9/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.7085 - accuracy: 0.8049 - val_loss: 1.0589 - val_accuracy: 0.7094\nEpoch 10/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.6791 - accuracy: 0.8149 - val_loss: 1.0626 - val_accuracy: 0.7051\nEpoch 11/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.6520 - accuracy: 0.8255 - val_loss: 1.1202 - val_accuracy: 0.7088\nEpoch 12/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.6323 - accuracy: 0.8310 - val_loss: 0.7810 - val_accuracy: 0.7899\nEpoch 13/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.6185 - accuracy: 0.8372 - val_loss: 0.8952 - val_accuracy: 0.7626\nEpoch 14/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.5979 - accuracy: 0.8432 - val_loss: 0.7217 - val_accuracy: 0.8079\nEpoch 15/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.5849 - accuracy: 0.8480 - val_loss: 0.9566 - val_accuracy: 0.7296\nEpoch 16/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 89ms/step - loss: 0.5739 - accuracy: 0.8505 - val_loss: 1.0309 - val_accuracy: 0.7191\nEpoch 17/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.5577 - accuracy: 0.8578 - val_loss: 0.7367 - val_accuracy: 0.8059\nEpoch 18/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.5452 - accuracy: 0.8606 - val_loss: 0.9232 - val_accuracy: 0.7564\nEpoch 19/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 89ms/step - loss: 0.5387 - accuracy: 0.8645 - val_loss: 0.7205 - val_accuracy: 0.8153\nEpoch 20/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.5250 - accuracy: 0.8682 - val_loss: 0.8266 - val_accuracy: 0.7979\nEpoch 21/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 89ms/step - loss: 0.5163 - accuracy: 0.8715 - val_loss: 0.7905 - val_accuracy: 0.7913\nEpoch 22/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 88ms/step - loss: 0.5151 - accuracy: 0.8718 - val_loss: 0.7442 - val_accuracy: 0.8120\nEpoch 23/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.5000 - accuracy: 0.8785 - val_loss: 0.6785 - val_accuracy: 0.8257\nEpoch 24/50\nLearning rate:  0.001\n391/391 [==============================] - 33s 85ms/step - loss: 0.4917 - accuracy: 0.8803 - val_loss: 0.7527 - val_accuracy: 0.8034\nEpoch 25/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.4926 - accuracy: 0.8811 - val_loss: 0.7202 - val_accuracy: 0.8219\nEpoch 26/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.4822 - accuracy: 0.8843 - val_loss: 0.8715 - val_accuracy: 0.7754\nEpoch 27/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 90ms/step - loss: 0.4711 - accuracy: 0.8882 - val_loss: 0.7747 - val_accuracy: 0.8011\nEpoch 28/50\nLearning rate:  0.001\n391/391 [==============================] - 36s 93ms/step - loss: 0.4680 - accuracy: 0.8888 - val_loss: 0.7921 - val_accuracy: 0.8000\nEpoch 29/50\nLearning rate:  0.001\n391/391 [==============================] - 37s 95ms/step - loss: 0.4649 - accuracy: 0.8904 - val_loss: 0.7845 - val_accuracy: 0.8043\nEpoch 30/50\nLearning rate:  0.001\n391/391 [==============================] - 38s 97ms/step - loss: 0.4565 - accuracy: 0.8933 - val_loss: 0.7495 - val_accuracy: 0.8137\nEpoch 31/50\nLearning rate:  0.001\n391/391 [==============================] - 37s 95ms/step - loss: 0.4519 - accuracy: 0.8964 - val_loss: 0.7597 - val_accuracy: 0.8153\nEpoch 32/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.4489 - accuracy: 0.8965 - val_loss: 0.8202 - val_accuracy: 0.7973\nEpoch 33/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 89ms/step - loss: 0.4424 - accuracy: 0.8985 - val_loss: 0.6948 - val_accuracy: 0.8243\nEpoch 34/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 90ms/step - loss: 0.4387 - accuracy: 0.8995 - val_loss: 0.6656 - val_accuracy: 0.8298\nEpoch 35/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.4370 - accuracy: 0.9006 - val_loss: 0.6421 - val_accuracy: 0.8422\nEpoch 36/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 91ms/step - loss: 0.4325 - accuracy: 0.9034 - val_loss: 0.7138 - val_accuracy: 0.8150\nEpoch 37/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 88ms/step - loss: 0.4313 - accuracy: 0.9024 - val_loss: 1.0455 - val_accuracy: 0.7521\nEpoch 38/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.4331 - accuracy: 0.9035 - val_loss: 0.6737 - val_accuracy: 0.8438\nEpoch 39/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.4199 - accuracy: 0.9065 - val_loss: 0.9455 - val_accuracy: 0.7722\nEpoch 40/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.4188 - accuracy: 0.9078 - val_loss: 0.6877 - val_accuracy: 0.8391\nEpoch 41/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.4193 - accuracy: 0.9083 - val_loss: 0.6764 - val_accuracy: 0.8283\nEpoch 42/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 86ms/step - loss: 0.4124 - accuracy: 0.9093 - val_loss: 0.7698 - val_accuracy: 0.8143\nEpoch 43/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 88ms/step - loss: 0.4087 - accuracy: 0.9107 - val_loss: 0.7125 - val_accuracy: 0.8235\nEpoch 44/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.4101 - accuracy: 0.9106 - val_loss: 0.8586 - val_accuracy: 0.8021\nEpoch 45/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 89ms/step - loss: 0.4081 - accuracy: 0.9120 - val_loss: 0.7750 - val_accuracy: 0.8135\nEpoch 46/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.4027 - accuracy: 0.9138 - val_loss: 0.7658 - val_accuracy: 0.8109\nEpoch 47/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.4010 - accuracy: 0.9139 - val_loss: 0.7342 - val_accuracy: 0.8330\nEpoch 48/50\nLearning rate:  0.001\n391/391 [==============================] - 35s 89ms/step - loss: 0.4019 - accuracy: 0.9136 - val_loss: 0.6612 - val_accuracy: 0.8464\nEpoch 49/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 87ms/step - loss: 0.3996 - accuracy: 0.9151 - val_loss: 0.6389 - val_accuracy: 0.8550\nEpoch 50/50\nLearning rate:  0.001\n391/391 [==============================] - 34s 88ms/step - loss: 0.3939 - accuracy: 0.9166 - val_loss: 0.7445 - val_accuracy: 0.8237\n","name":"stdout"},{"output_type":"stream","text":"10000/10000 [==============================] - 3s 255us/step\nTest loss: 0.7445273817062378\nTest accuracy: 0.8237000107765198\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}