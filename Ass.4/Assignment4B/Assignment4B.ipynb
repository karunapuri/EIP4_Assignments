{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport keras\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.datasets import cifar10\nimport numpy as np\nimport os\n\n# Training parameters\nbatch_size = 64  # orig paper trained all networks with batch_size=128\nepochs = 50\ndata_augmentation = False\nnum_classes = 10\nrandom_erasing = True\n\n# Subtracting pixel mean improves accuracy\nsubtract_pixel_mean = True\nn = 3\n\n# Model version\n# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\nversion = 1\n\n# Computed depth from supplied model parameter n\nif version == 1:\n    depth = n * 6 + 2\nelif version == 2:\n    depth = n * 9 + 2\n\n# Model name, depth and version\nmodel_type = 'ResNet%dv%d' % (depth, version)\n\n# Load the CIFAR10 data.\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# Input image dimensions.\ninput_shape = x_train.shape[1:]\n\n# Normalize data.\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\n# If subtract pixel mean is enabled\nif subtract_pixel_mean:\n    x_train_mean = np.mean(x_train, axis=0)\n    x_train -= x_train_mean\n    x_test -= x_train_mean\n\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\nprint('y_train shape:', y_train.shape)\n\n# Convert class vectors to binary class matrices.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\ndef lr_schedule(epoch):\n    lr = 1e-3\n    if epoch > 180:\n        lr *= 0.5e-3\n    elif epoch > 160:\n        lr *= 1e-3\n    elif epoch > 120:\n        lr *= 1e-2\n    elif epoch > 80:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr\n\ndef resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x\n\n\ndef resnet_v1(input_shape, depth, num_classes=10):\n    if (depth - 2) % 6 != 0:\n        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n    # Start model definition.\n    num_filters = 16\n    num_res_blocks = int((depth - 2) / 6)\n\n    inputs = Input(shape=input_shape)\n    x = resnet_layer(inputs=inputs)\n    # Instantiate the stack of residual units\n    for stack in range(3):\n        for res_block in range(num_res_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                strides = 2  # downsample\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             strides=strides)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n            x = Activation('relu')(x)\n        num_filters *= 2\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\ndef resnet_v2(input_shape, depth, num_classes=10):\n    if (depth - 2) % 9 != 0:\n        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n    # Start model definition.\n    num_filters_in = 16\n    num_res_blocks = int((depth - 2) / 9)\n\n    inputs = Input(shape=input_shape)\n    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n    x = resnet_layer(inputs=inputs,\n                     num_filters=num_filters_in,\n                     conv_first=True)\n\n    # Instantiate the stack of residual units\n    for stage in range(3):\n        for res_block in range(num_res_blocks):\n            activation = 'relu'\n            batch_normalization = True\n            strides = 1\n            if stage == 0:\n                num_filters_out = num_filters_in * 4\n                if res_block == 0:  # first layer and first stage\n                    activation = None\n                    batch_normalization = False\n            else:\n                num_filters_out = num_filters_in * 2\n                if res_block == 0:  # first layer but not first stage\n                    strides = 2    # downsample\n\n            # bottleneck residual unit\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters_in,\n                             kernel_size=1,\n                             strides=strides,\n                             activation=activation,\n                             batch_normalization=batch_normalization,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_in,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_out,\n                             kernel_size=1,\n                             conv_first=False)\n            if res_block == 0:\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters_out,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n\n        num_filters_in = num_filters_out\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='softmax',\n                    kernel_initializer='he_normal')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\n\nif version == 2:\n    model = resnet_v2(input_shape=input_shape, depth=depth)\nelse:\n    model = resnet_v1(input_shape=input_shape, depth=depth)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=0),\n              metrics=['accuracy'])\nmodel.summary()\nprint(model_type)\n\n# Prepare model model saving directory.\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nfilepath = os.path.join(save_dir, model_name)\n\n# Prepare callbacks for model saving and for learning rate adjustment.\ncheckpoint = ModelCheckpoint(filepath=filepath,\n                             monitor='val_acc',\n                             verbose=1,\n                             save_best_only=True)\n\nlr_scheduler = LearningRateScheduler(lr_schedule)\n\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               min_lr=0.5e-6)\n\ncallbacks = [checkpoint, lr_reducer, lr_scheduler]\n\n# Run training, with or without data augmentation.\nif not data_augmentation:\n    print('Not using data augmentation.')\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True,\n              callbacks=callbacks)\nelse:\n    print('Using real-time data augmentation.')\n    # This will do preprocessing and realtime data augmentation:\n    datagen = ImageDataGenerator(\n        # set input mean to 0 over the dataset\n        featurewise_center=False,\n        # set each sample mean to 0\n        samplewise_center=False,\n        # divide inputs by std of dataset\n        featurewise_std_normalization=False,\n        # divide each input by its std\n        samplewise_std_normalization=False,\n        # apply ZCA whitening\n        zca_whitening=False,\n        # epsilon for ZCA whitening\n        zca_epsilon=1e-06,\n        # randomly rotate images in the range (deg 0 to 180)\n        rotation_range=0,\n        # randomly shift images horizontally\n        width_shift_range=0.1,\n        # randomly shift images vertically\n        height_shift_range=0.1,\n        # set range for random shear\n        shear_range=0.,\n        # set range for random zoom\n        zoom_range=0.,\n        # set range for random channel shifts\n        channel_shift_range=0.,\n        # set mode for filling points outside the input boundaries\n        fill_mode='nearest',\n        # value used for fill_mode = \"constant\"\n        cval=0.,\n        # randomly flip images\n        horizontal_flip=True,\n        # randomly flip images\n        vertical_flip=False,\n        # set rescaling factor (applied before any other transformation)\n        rescale=None,\n        # set function that will be applied on each input\n        preprocessing_function=None,\n        # image data format, either \"channels_first\" or \"channels_last\"\n        data_format=None,\n        # fraction of images reserved for validation (strictly between 0 and 1)\n        validation_split=0.0)\n\n    datagen.fit(x_train)\n\n    # Fit the model on the batches generated by datagen.flow().\n    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                        validation_data=(x_test, y_test),\n                        epochs=epochs, verbose=1, workers=4,\n                        callbacks=callbacks)\n\n# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":3,"outputs":[{"output_type":"stream","text":"x_train shape: (50000, 32, 32, 3)\n50000 train samples\n10000 test samples\ny_train shape: (50000, 1)\nModel: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n__________________________________________________________________________________________________\nconv2d_43 (Conv2D)              (None, 32, 32, 16)   448         input_3[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_39 (BatchNo (None, 32, 32, 16)   64          conv2d_43[0][0]                  \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 32, 32, 16)   0           batch_normalization_39[0][0]     \n__________________________________________________________________________________________________\nconv2d_44 (Conv2D)              (None, 32, 32, 16)   2320        activation_39[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_40 (BatchNo (None, 32, 32, 16)   64          conv2d_44[0][0]                  \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 32, 32, 16)   0           batch_normalization_40[0][0]     \n__________________________________________________________________________________________________\nconv2d_45 (Conv2D)              (None, 32, 32, 16)   2320        activation_40[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_41 (BatchNo (None, 32, 32, 16)   64          conv2d_45[0][0]                  \n__________________________________________________________________________________________________\nadd_19 (Add)                    (None, 32, 32, 16)   0           activation_39[0][0]              \n                                                                 batch_normalization_41[0][0]     \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 32, 32, 16)   0           add_19[0][0]                     \n__________________________________________________________________________________________________\nconv2d_46 (Conv2D)              (None, 32, 32, 16)   2320        activation_41[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_42 (BatchNo (None, 32, 32, 16)   64          conv2d_46[0][0]                  \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 32, 32, 16)   0           batch_normalization_42[0][0]     \n__________________________________________________________________________________________________\nconv2d_47 (Conv2D)              (None, 32, 32, 16)   2320        activation_42[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_43 (BatchNo (None, 32, 32, 16)   64          conv2d_47[0][0]                  \n__________________________________________________________________________________________________\nadd_20 (Add)                    (None, 32, 32, 16)   0           activation_41[0][0]              \n                                                                 batch_normalization_43[0][0]     \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 32, 32, 16)   0           add_20[0][0]                     \n__________________________________________________________________________________________________\nconv2d_48 (Conv2D)              (None, 32, 32, 16)   2320        activation_43[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_44 (BatchNo (None, 32, 32, 16)   64          conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 32, 32, 16)   0           batch_normalization_44[0][0]     \n__________________________________________________________________________________________________\nconv2d_49 (Conv2D)              (None, 32, 32, 16)   2320        activation_44[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_45 (BatchNo (None, 32, 32, 16)   64          conv2d_49[0][0]                  \n__________________________________________________________________________________________________\nadd_21 (Add)                    (None, 32, 32, 16)   0           activation_43[0][0]              \n                                                                 batch_normalization_45[0][0]     \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 32, 32, 16)   0           add_21[0][0]                     \n__________________________________________________________________________________________________\nconv2d_50 (Conv2D)              (None, 16, 16, 32)   4640        activation_45[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_46 (BatchNo (None, 16, 16, 32)   128         conv2d_50[0][0]                  \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_46[0][0]     \n__________________________________________________________________________________________________\nconv2d_51 (Conv2D)              (None, 16, 16, 32)   9248        activation_46[0][0]              \n__________________________________________________________________________________________________\nconv2d_52 (Conv2D)              (None, 16, 16, 32)   544         activation_45[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_47 (BatchNo (None, 16, 16, 32)   128         conv2d_51[0][0]                  \n__________________________________________________________________________________________________\nadd_22 (Add)                    (None, 16, 16, 32)   0           conv2d_52[0][0]                  \n                                                                 batch_normalization_47[0][0]     \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 16, 16, 32)   0           add_22[0][0]                     \n__________________________________________________________________________________________________\nconv2d_53 (Conv2D)              (None, 16, 16, 32)   9248        activation_47[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_48 (BatchNo (None, 16, 16, 32)   128         conv2d_53[0][0]                  \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 16, 16, 32)   0           batch_normalization_48[0][0]     \n__________________________________________________________________________________________________\nconv2d_54 (Conv2D)              (None, 16, 16, 32)   9248        activation_48[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_49 (BatchNo (None, 16, 16, 32)   128         conv2d_54[0][0]                  \n__________________________________________________________________________________________________\nadd_23 (Add)                    (None, 16, 16, 32)   0           activation_47[0][0]              \n                                                                 batch_normalization_49[0][0]     \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 16, 16, 32)   0           add_23[0][0]                     \n__________________________________________________________________________________________________\nconv2d_55 (Conv2D)              (None, 16, 16, 32)   9248        activation_49[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_50 (BatchNo (None, 16, 16, 32)   128         conv2d_55[0][0]                  \n__________________________________________________________________________________________________\nactivation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_50[0][0]     \n__________________________________________________________________________________________________\nconv2d_56 (Conv2D)              (None, 16, 16, 32)   9248        activation_50[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_51 (BatchNo (None, 16, 16, 32)   128         conv2d_56[0][0]                  \n__________________________________________________________________________________________________\nadd_24 (Add)                    (None, 16, 16, 32)   0           activation_49[0][0]              \n                                                                 batch_normalization_51[0][0]     \n__________________________________________________________________________________________________\nactivation_51 (Activation)      (None, 16, 16, 32)   0           add_24[0][0]                     \n__________________________________________________________________________________________________\nconv2d_57 (Conv2D)              (None, 8, 8, 64)     18496       activation_51[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_57[0][0]                  \n__________________________________________________________________________________________________\nactivation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     \n__________________________________________________________________________________________________\nconv2d_58 (Conv2D)              (None, 8, 8, 64)     36928       activation_52[0][0]              \n__________________________________________________________________________________________________\nconv2d_59 (Conv2D)              (None, 8, 8, 64)     2112        activation_51[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nadd_25 (Add)                    (None, 8, 8, 64)     0           conv2d_59[0][0]                  \n                                                                 batch_normalization_53[0][0]     \n__________________________________________________________________________________________________\nactivation_53 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     \n__________________________________________________________________________________________________\nconv2d_60 (Conv2D)              (None, 8, 8, 64)     36928       activation_53[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_54 (BatchNo (None, 8, 8, 64)     256         conv2d_60[0][0]                  \n__________________________________________________________________________________________________\nactivation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     \n__________________________________________________________________________________________________\nconv2d_61 (Conv2D)              (None, 8, 8, 64)     36928       activation_54[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_55 (BatchNo (None, 8, 8, 64)     256         conv2d_61[0][0]                  \n__________________________________________________________________________________________________\nadd_26 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              \n                                                                 batch_normalization_55[0][0]     \n__________________________________________________________________________________________________\nactivation_55 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     \n__________________________________________________________________________________________________\nconv2d_62 (Conv2D)              (None, 8, 8, 64)     36928       activation_55[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_56 (BatchNo (None, 8, 8, 64)     256         conv2d_62[0][0]                  \n__________________________________________________________________________________________________\nactivation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_56[0][0]     \n__________________________________________________________________________________________________\nconv2d_63 (Conv2D)              (None, 8, 8, 64)     36928       activation_56[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_57 (BatchNo (None, 8, 8, 64)     256         conv2d_63[0][0]                  \n__________________________________________________________________________________________________\nadd_27 (Add)                    (None, 8, 8, 64)     0           activation_55[0][0]              \n                                                                 batch_normalization_57[0][0]     \n__________________________________________________________________________________________________\nactivation_57 (Activation)      (None, 8, 8, 64)     0           add_27[0][0]                     \n__________________________________________________________________________________________________\naverage_pooling2d_3 (AveragePoo (None, 1, 1, 64)     0           activation_57[0][0]              \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 64)           0           average_pooling2d_3[0][0]        \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 10)           650         flatten_3[0][0]                  \n==================================================================================================\nTotal params: 274,442\nTrainable params: 273,066\nNon-trainable params: 1,376\n__________________________________________________________________________________________________\nResNet20v1\nNot using data augmentation.\n","name":"stdout"},{"output_type":"stream","text":"Train on 50000 samples, validate on 10000 samples\nEpoch 1/50\nLearning rate:  0.001\n50000/50000 [==============================] - 45s 903us/step - loss: 1.5010 - accuracy: 0.5120 - val_loss: 1.5172 - val_accuracy: 0.5150\nEpoch 2/50\nLearning rate:  0.001\n  192/50000 [..............................] - ETA: 37s - loss: 1.2927 - accuracy: 0.5729","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n  'skipping.' % (self.monitor), RuntimeWarning)\n","name":"stderr"},{"output_type":"stream","text":"50000/50000 [==============================] - 36s 725us/step - loss: 1.0970 - accuracy: 0.6651 - val_loss: 1.2235 - val_accuracy: 0.6165\nEpoch 3/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 722us/step - loss: 0.9291 - accuracy: 0.7269 - val_loss: 1.1859 - val_accuracy: 0.6432\nEpoch 4/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 716us/step - loss: 0.8148 - accuracy: 0.7696 - val_loss: 1.3001 - val_accuracy: 0.6356\nEpoch 5/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 716us/step - loss: 0.7368 - accuracy: 0.7993 - val_loss: 1.1284 - val_accuracy: 0.6843\nEpoch 6/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 715us/step - loss: 0.6774 - accuracy: 0.8208 - val_loss: 1.0422 - val_accuracy: 0.7198\nEpoch 7/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 720us/step - loss: 0.6241 - accuracy: 0.8391 - val_loss: 1.1243 - val_accuracy: 0.6989\nEpoch 8/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 728us/step - loss: 0.5817 - accuracy: 0.8551 - val_loss: 1.0327 - val_accuracy: 0.7265\nEpoch 9/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 721us/step - loss: 0.5399 - accuracy: 0.8723 - val_loss: 1.1357 - val_accuracy: 0.7200\nEpoch 10/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 716us/step - loss: 0.5143 - accuracy: 0.8826 - val_loss: 1.1087 - val_accuracy: 0.7279\nEpoch 11/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 718us/step - loss: 0.4835 - accuracy: 0.8943 - val_loss: 1.1322 - val_accuracy: 0.7184\nEpoch 12/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 723us/step - loss: 0.4586 - accuracy: 0.9035 - val_loss: 1.1750 - val_accuracy: 0.7299\nEpoch 13/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 725us/step - loss: 0.4358 - accuracy: 0.9137 - val_loss: 1.0783 - val_accuracy: 0.7506\nEpoch 14/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 723us/step - loss: 0.4237 - accuracy: 0.9192 - val_loss: 1.1162 - val_accuracy: 0.7473\nEpoch 15/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 719us/step - loss: 0.4088 - accuracy: 0.9255 - val_loss: 1.6973 - val_accuracy: 0.6435\nEpoch 16/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 722us/step - loss: 0.3977 - accuracy: 0.9319 - val_loss: 2.1033 - val_accuracy: 0.6205\nEpoch 17/50\nLearning rate:  0.001\n50000/50000 [==============================] - 37s 735us/step - loss: 0.3881 - accuracy: 0.9359 - val_loss: 1.2465 - val_accuracy: 0.7355\nEpoch 18/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 722us/step - loss: 0.3814 - accuracy: 0.9397 - val_loss: 1.4800 - val_accuracy: 0.7097\nEpoch 19/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 721us/step - loss: 0.3778 - accuracy: 0.9415 - val_loss: 1.3876 - val_accuracy: 0.7276\nEpoch 20/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 718us/step - loss: 0.3751 - accuracy: 0.9442 - val_loss: 1.1978 - val_accuracy: 0.7413\nEpoch 21/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 715us/step - loss: 0.3675 - accuracy: 0.9469 - val_loss: 1.3712 - val_accuracy: 0.7400\nEpoch 22/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 715us/step - loss: 0.3569 - accuracy: 0.9509 - val_loss: 1.2087 - val_accuracy: 0.7691\nEpoch 23/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 717us/step - loss: 0.3642 - accuracy: 0.9484 - val_loss: 1.4207 - val_accuracy: 0.7397\nEpoch 24/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 714us/step - loss: 0.3625 - accuracy: 0.9491 - val_loss: 1.4099 - val_accuracy: 0.7327\nEpoch 25/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 729us/step - loss: 0.3584 - accuracy: 0.9535 - val_loss: 1.3134 - val_accuracy: 0.7655\nEpoch 26/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 726us/step - loss: 0.3558 - accuracy: 0.9544 - val_loss: 1.2897 - val_accuracy: 0.7524\nEpoch 27/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 724us/step - loss: 0.3549 - accuracy: 0.9554 - val_loss: 1.4929 - val_accuracy: 0.7426\nEpoch 28/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 724us/step - loss: 0.3576 - accuracy: 0.9542 - val_loss: 1.4504 - val_accuracy: 0.7402\nEpoch 29/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 719us/step - loss: 0.3538 - accuracy: 0.9564 - val_loss: 1.4328 - val_accuracy: 0.7359\nEpoch 30/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 719us/step - loss: 0.3559 - accuracy: 0.9559 - val_loss: 1.4688 - val_accuracy: 0.7326\nEpoch 31/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 723us/step - loss: 0.3462 - accuracy: 0.9598 - val_loss: 1.3114 - val_accuracy: 0.7708\nEpoch 32/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 725us/step - loss: 0.3502 - accuracy: 0.9592 - val_loss: 1.7006 - val_accuracy: 0.7246\nEpoch 33/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 723us/step - loss: 0.3549 - accuracy: 0.9580 - val_loss: 1.3350 - val_accuracy: 0.7598\nEpoch 34/50\nLearning rate:  0.001\n50000/50000 [==============================] - 37s 741us/step - loss: 0.3500 - accuracy: 0.9600 - val_loss: 1.3563 - val_accuracy: 0.7579\nEpoch 35/50\nLearning rate:  0.001\n50000/50000 [==============================] - 37s 731us/step - loss: 0.3456 - accuracy: 0.9618 - val_loss: 1.6030 - val_accuracy: 0.7098\nEpoch 36/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 726us/step - loss: 0.3502 - accuracy: 0.9596 - val_loss: 1.4580 - val_accuracy: 0.7399\nEpoch 37/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 719us/step - loss: 0.3486 - accuracy: 0.9608 - val_loss: 1.4627 - val_accuracy: 0.7456\nEpoch 38/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 719us/step - loss: 0.3502 - accuracy: 0.9601 - val_loss: 1.6466 - val_accuracy: 0.7319\nEpoch 39/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 721us/step - loss: 0.3418 - accuracy: 0.9631 - val_loss: 2.0795 - val_accuracy: 0.6708\nEpoch 40/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 721us/step - loss: 0.3437 - accuracy: 0.9619 - val_loss: 1.6143 - val_accuracy: 0.7288\nEpoch 41/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 719us/step - loss: 0.3470 - accuracy: 0.9613 - val_loss: 1.4240 - val_accuracy: 0.7517\nEpoch 42/50\nLearning rate:  0.001\n50000/50000 [==============================] - 37s 735us/step - loss: 0.3473 - accuracy: 0.9631 - val_loss: 1.4813 - val_accuracy: 0.7347\nEpoch 43/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 723us/step - loss: 0.3406 - accuracy: 0.9642 - val_loss: 1.4652 - val_accuracy: 0.7632\nEpoch 44/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 723us/step - loss: 0.3418 - accuracy: 0.9639 - val_loss: 2.9516 - val_accuracy: 0.6335\nEpoch 45/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 719us/step - loss: 0.3436 - accuracy: 0.9626 - val_loss: 1.3085 - val_accuracy: 0.7577\nEpoch 46/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 721us/step - loss: 0.3480 - accuracy: 0.9618 - val_loss: 1.5804 - val_accuracy: 0.7318\nEpoch 47/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 718us/step - loss: 0.3400 - accuracy: 0.9645 - val_loss: 1.3458 - val_accuracy: 0.7641\nEpoch 48/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 719us/step - loss: 0.3436 - accuracy: 0.9642 - val_loss: 1.4049 - val_accuracy: 0.7611\nEpoch 49/50\nLearning rate:  0.001\n50000/50000 [==============================] - 36s 722us/step - loss: 0.3361 - accuracy: 0.9668 - val_loss: 1.6016 - val_accuracy: 0.7339\n","name":"stdout"},{"output_type":"stream","text":"Epoch 50/50\nLearning rate:  0.001\n50000/50000 [==============================] - 37s 732us/step - loss: 0.3416 - accuracy: 0.9641 - val_loss: 1.4102 - val_accuracy: 0.7407\n10000/10000 [==============================] - 3s 294us/step\nTest loss: 1.410179568862915\nTest accuracy: 0.7407000064849854\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}