Using TensorFlow backend.
Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
170500096/170498071 [==============================] - 4s 0us/step
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
y_train shape: (50000, 1)
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_10[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           batch_normalization_10[0][0]     
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               
                                                                 batch_normalization_12[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              
                                                                 batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           batch_normalization_17[0][0]     
                                                                 batch_normalization_16[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 274,826
Trainable params: 273,258
Non-trainable params: 1,568
__________________________________________________________________________________________________
ResNet20v1
Using real-time data augmentation.
Epoch 1/50
Learning rate:  0.001
391/391 [==============================] - 48s 122ms/step - loss: 1.6513 - accuracy: 0.4543 - val_loss: 1.8140 - val_accuracy: 0.4527
Epoch 2/50
Learning rate:  0.001
  2/391 [..............................] - ETA: 25s - loss: 1.3259 - accuracy: 0.5859
/opt/conda/lib/python3.6/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.
  'skipping.' % (self.monitor), RuntimeWarning)
391/391 [==============================] - 37s 94ms/step - loss: 1.2736 - accuracy: 0.5992 - val_loss: 2.1325 - val_accuracy: 0.4818
Epoch 3/50
Learning rate:  0.001
391/391 [==============================] - 37s 94ms/step - loss: 1.0933 - accuracy: 0.6667 - val_loss: 1.6182 - val_accuracy: 0.5369
Epoch 4/50
Learning rate:  0.001
391/391 [==============================] - 37s 94ms/step - loss: 0.9666 - accuracy: 0.7127 - val_loss: 1.5333 - val_accuracy: 0.5887
Epoch 5/50
Learning rate:  0.001
391/391 [==============================] - 37s 94ms/step - loss: 0.8865 - accuracy: 0.7427 - val_loss: 1.0348 - val_accuracy: 0.6951
Epoch 6/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.8236 - accuracy: 0.7642 - val_loss: 0.9674 - val_accuracy: 0.7220
Epoch 7/50
Learning rate:  0.001
391/391 [==============================] - 38s 96ms/step - loss: 0.7791 - accuracy: 0.7821 - val_loss: 0.9433 - val_accuracy: 0.7272
Epoch 8/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.7467 - accuracy: 0.7913 - val_loss: 0.9438 - val_accuracy: 0.7326
Epoch 9/50
Learning rate:  0.001
391/391 [==============================] - 37s 93ms/step - loss: 0.7076 - accuracy: 0.8060 - val_loss: 1.2718 - val_accuracy: 0.6587
Epoch 10/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.6797 - accuracy: 0.8161 - val_loss: 0.8884 - val_accuracy: 0.7603
Epoch 11/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.6625 - accuracy: 0.8203 - val_loss: 1.0522 - val_accuracy: 0.7201
Epoch 12/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.6403 - accuracy: 0.8291 - val_loss: 0.8831 - val_accuracy: 0.7584
Epoch 13/50
Learning rate:  0.001
391/391 [==============================] - 37s 93ms/step - loss: 0.6219 - accuracy: 0.8348 - val_loss: 0.7556 - val_accuracy: 0.7954
Epoch 14/50
Learning rate:  0.001
391/391 [==============================] - 37s 94ms/step - loss: 0.6043 - accuracy: 0.8398 - val_loss: 0.8880 - val_accuracy: 0.7603
Epoch 15/50
Learning rate:  0.001
391/391 [==============================] - 37s 93ms/step - loss: 0.5873 - accuracy: 0.8485 - val_loss: 0.8864 - val_accuracy: 0.7442
Epoch 16/50
Learning rate:  0.001
391/391 [==============================] - 37s 95ms/step - loss: 0.5736 - accuracy: 0.8537 - val_loss: 0.9129 - val_accuracy: 0.7542
Epoch 17/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.5620 - accuracy: 0.8558 - val_loss: 0.7427 - val_accuracy: 0.8047
Epoch 18/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.5487 - accuracy: 0.8598 - val_loss: 0.7160 - val_accuracy: 0.8127
Epoch 19/50
Learning rate:  0.001
391/391 [==============================] - 36s 92ms/step - loss: 0.5385 - accuracy: 0.8631 - val_loss: 1.0551 - val_accuracy: 0.7416
Epoch 20/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.5250 - accuracy: 0.8689 - val_loss: 0.9284 - val_accuracy: 0.7469
Epoch 21/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.5226 - accuracy: 0.8688 - val_loss: 0.7064 - val_accuracy: 0.8207
Epoch 22/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.5090 - accuracy: 0.8740 - val_loss: 0.9658 - val_accuracy: 0.7543
Epoch 23/50
Learning rate:  0.001
391/391 [==============================] - 37s 93ms/step - loss: 0.5012 - accuracy: 0.8780 - val_loss: 0.7719 - val_accuracy: 0.8072
Epoch 24/50
Learning rate:  0.001
391/391 [==============================] - 37s 94ms/step - loss: 0.4946 - accuracy: 0.8809 - val_loss: 0.8302 - val_accuracy: 0.7861
Epoch 25/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.4882 - accuracy: 0.8827 - val_loss: 0.6447 - val_accuracy: 0.8336
Epoch 26/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.4847 - accuracy: 0.8834 - val_loss: 0.7962 - val_accuracy: 0.7957
Epoch 27/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.4740 - accuracy: 0.8873 - val_loss: 0.8509 - val_accuracy: 0.7935
Epoch 28/50
Learning rate:  0.001
391/391 [==============================] - 36s 92ms/step - loss: 0.4675 - accuracy: 0.8889 - val_loss: 0.7836 - val_accuracy: 0.8028
Epoch 29/50
Learning rate:  0.001
391/391 [==============================] - 36s 92ms/step - loss: 0.4629 - accuracy: 0.8911 - val_loss: 0.7526 - val_accuracy: 0.8087
Epoch 30/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.4584 - accuracy: 0.8938 - val_loss: 0.7389 - val_accuracy: 0.8112
Epoch 31/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.4503 - accuracy: 0.8955 - val_loss: 0.7932 - val_accuracy: 0.8023
Epoch 32/50
Learning rate:  0.001
391/391 [==============================] - 37s 94ms/step - loss: 0.4528 - accuracy: 0.8938 - val_loss: 0.6341 - val_accuracy: 0.8414
Epoch 33/50
Learning rate:  0.001
391/391 [==============================] - 36s 92ms/step - loss: 0.4432 - accuracy: 0.8987 - val_loss: 0.8309 - val_accuracy: 0.7927
Epoch 34/50
Learning rate:  0.001
391/391 [==============================] - 36s 92ms/step - loss: 0.4427 - accuracy: 0.8982 - val_loss: 0.6889 - val_accuracy: 0.8353
Epoch 35/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.4358 - accuracy: 0.9018 - val_loss: 0.7145 - val_accuracy: 0.8182
Epoch 36/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.4354 - accuracy: 0.9019 - val_loss: 0.7718 - val_accuracy: 0.8223
Epoch 37/50
Learning rate:  0.001
391/391 [==============================] - 36s 92ms/step - loss: 0.4341 - accuracy: 0.9026 - val_loss: 0.7661 - val_accuracy: 0.8131
Epoch 38/50
Learning rate:  0.001
391/391 [==============================] - 37s 94ms/step - loss: 0.4276 - accuracy: 0.9037 - val_loss: 1.0578 - val_accuracy: 0.7414
Epoch 39/50
Learning rate:  0.001
391/391 [==============================] - 37s 95ms/step - loss: 0.4246 - accuracy: 0.9052 - val_loss: 0.6868 - val_accuracy: 0.8338
Epoch 40/50
Learning rate:  0.001
391/391 [==============================] - 37s 94ms/step - loss: 0.4186 - accuracy: 0.9071 - val_loss: 0.7592 - val_accuracy: 0.8175
Epoch 41/50
Learning rate:  0.001
391/391 [==============================] - 38s 96ms/step - loss: 0.4185 - accuracy: 0.9072 - val_loss: 0.7892 - val_accuracy: 0.8106
Epoch 42/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.4150 - accuracy: 0.9095 - val_loss: 0.8297 - val_accuracy: 0.8010
Epoch 43/50
Learning rate:  0.001
391/391 [==============================] - 37s 94ms/step - loss: 0.4111 - accuracy: 0.9104 - val_loss: 0.7547 - val_accuracy: 0.8256
Epoch 44/50
Learning rate:  0.001
391/391 [==============================] - 37s 93ms/step - loss: 0.4109 - accuracy: 0.9098 - val_loss: 0.6933 - val_accuracy: 0.8344
Epoch 45/50
Learning rate:  0.001
391/391 [==============================] - 37s 94ms/step - loss: 0.4040 - accuracy: 0.9118 - val_loss: 0.6548 - val_accuracy: 0.8439
Epoch 46/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.4099 - accuracy: 0.9114 - val_loss: 0.7506 - val_accuracy: 0.8174
Epoch 47/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.4018 - accuracy: 0.9137 - val_loss: 0.8675 - val_accuracy: 0.7926
Epoch 48/50
Learning rate:  0.001
391/391 [==============================] - 36s 92ms/step - loss: 0.4008 - accuracy: 0.9140 - val_loss: 0.7457 - val_accuracy: 0.8283
Epoch 49/50
Learning rate:  0.001
391/391 [==============================] - 36s 93ms/step - loss: 0.3957 - accuracy: 0.9161 - val_loss: 0.9209 - val_accuracy: 0.7968
Epoch 50/50
Learning rate:  0.001
391/391 [==============================] - 36s 91ms/step - loss: 0.3934 - accuracy: 0.9173 - val_loss: 0.6418 - val_accuracy: 0.8465
10000/10000 [==============================] - 3s 265us/step
Test loss: 0.6417574576377869
Test accuracy: 0.8464999794960022
